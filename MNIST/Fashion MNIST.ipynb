{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "dataset = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 10s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing set\n",
    "(X_train, y_train), (X_test, y_test) = dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 1), (60000,), (10000,), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape, y_train.shape, y_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00392157 0.         0.         0.05098039 0.28627451 0.\n",
      "  0.         0.00392157 0.01568627 0.         0.         0.\n",
      "  0.         0.00392157 0.00392157 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725\n",
      "  0.21176471 0.         0.         0.         0.00392157 0.01176471\n",
      "  0.01568627 0.         0.         0.01176471]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02352941 0.         0.4        0.8        0.69019608 0.5254902\n",
      "  0.56470588 0.48235294 0.09019608 0.         0.         0.\n",
      "  0.         0.04705882 0.03921569 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n",
      "  0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n",
      "  0.30196078 0.50980392 0.28235294 0.05882353]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882\n",
      "  0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902\n",
      "  0.55294118 0.34509804 0.6745098  0.25882353]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.00392157 0.00392157\n",
      "  0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922\n",
      "  0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922\n",
      "  0.48235294 0.76862745 0.89803922 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n",
      "  0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n",
      "  0.8745098  0.96078431 0.67843137 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059\n",
      "  0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098\n",
      "  0.8627451  0.95294118 0.79215686 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.01176471 0.\n",
      "  0.04705882 0.85882353 0.8627451  0.83137255 0.85490196 0.75294118\n",
      "  0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255\n",
      "  0.88627451 0.77254902 0.81960784 0.20392157]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.02352941 0.\n",
      "  0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n",
      "  0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n",
      "  0.96078431 0.46666667 0.65490196 0.21960784]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01568627 0.         0.\n",
      "  0.21568627 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647\n",
      "  0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039\n",
      "  0.85098039 0.81960784 0.36078431 0.        ]\n",
      " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098\n",
      "  0.00784314 0.         0.         0.         0.         0.\n",
      "  0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353\n",
      "  0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725\n",
      "  0.85490196 1.         0.30196078 0.        ]\n",
      " [0.         0.01176471 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.24313725 0.56862745 0.8\n",
      "  0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n",
      "  0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n",
      "  0.87843137 0.95686275 0.62352941 0.        ]\n",
      " [0.         0.         0.         0.         0.07058824 0.17254902\n",
      "  0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824\n",
      "  0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078\n",
      "  0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902\n",
      "  0.91372549 0.93333333 0.84313725 0.        ]\n",
      " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667\n",
      "  0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784\n",
      "  0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098\n",
      "  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098\n",
      "  0.8627451  0.90980392 0.96470588 0.        ]\n",
      " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n",
      "  0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n",
      "  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n",
      "  0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n",
      "  0.87058824 0.89411765 0.88235294 0.        ]\n",
      " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922\n",
      "  0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725\n",
      "  0.85098039 0.94509804 0.25490196 0.28627451 0.41568627 0.45882353\n",
      "  0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098\n",
      "  0.8745098  0.87843137 0.89803922 0.11372549]\n",
      " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157\n",
      "  0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314\n",
      "  0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431\n",
      "  0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824\n",
      "  0.8627451  0.86666667 0.90196078 0.2627451 ]\n",
      " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n",
      "  0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n",
      "  0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n",
      "  0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n",
      "  0.70980392 0.80392157 0.80784314 0.45098039]\n",
      " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824\n",
      "  0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471\n",
      "  0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961\n",
      "  0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471\n",
      "  0.65490196 0.69411765 0.82352941 0.36078431]\n",
      " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961\n",
      "  0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549\n",
      "  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784\n",
      "  0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431\n",
      "  0.75294118 0.84705882 0.66666667 0.        ]\n",
      " [0.00784314 0.         0.         0.         0.25882353 0.78431373\n",
      "  0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n",
      "  0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n",
      "  0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n",
      "  0.38823529 0.22745098 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431\n",
      "  0.1372549  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2016x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visulizing the data \n",
    "\n",
    "print(X_train[0].squeeze())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# plt.gray()\n",
    "plt.subplots(figsize=(28, 10))\n",
    "plt.grid(False)\n",
    "plt.imshow(X_train[0].squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data \n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "X_train = X_train/255.0\n",
    "X_test =X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "class myCallbacks(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.99):\n",
    "            print(\"\\nReached accuracy 99% stopping training\\n\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "            \n",
    "callbacks = myCallbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 126)               201726    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1270      \n",
      "=================================================================\n",
      "Total params: 240,564\n",
      "Trainable params: 240,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the neural net with two convolutional layers\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(126, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 28s 468us/sample - loss: 0.2972 - accuracy: 0.8910\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 31s 510us/sample - loss: 0.2471 - accuracy: 0.9082\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 32s 529us/sample - loss: 0.2132 - accuracy: 0.9203\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 31s 519us/sample - loss: 0.1868 - accuracy: 0.9295\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 29s 490us/sample - loss: 0.1638 - accuracy: 0.9380\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 31s 519us/sample - loss: 0.1460 - accuracy: 0.9452\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 30s 496us/sample - loss: 0.1283 - accuracy: 0.9521\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 31s 512us/sample - loss: 0.1136 - accuracy: 0.9570\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 32s 525us/sample - loss: 0.0991 - accuracy: 0.9626\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 31s 509us/sample - loss: 0.0879 - accuracy: 0.9671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb0cc748320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling and fittting the neural net\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train,\n",
    "         y_train, \n",
    "         epochs=10,\n",
    "          callbacks=[callbacks]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 126)               1362942   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1270      \n",
      "=================================================================\n",
      "Total params: 1,364,852\n",
      "Trainable params: 1,364,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the neural net with 1 convolutional layers\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(126, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 0.3780 - accuracy: 0.8636\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 27s 447us/sample - loss: 0.2555 - accuracy: 0.9074\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 27s 445us/sample - loss: 0.2115 - accuracy: 0.9226\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 26s 433us/sample - loss: 0.1807 - accuracy: 0.9330\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 0.1536 - accuracy: 0.9429\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 29s 490us/sample - loss: 0.1290 - accuracy: 0.9526\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 28s 460us/sample - loss: 0.1099 - accuracy: 0.9596\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 28s 468us/sample - loss: 0.0928 - accuracy: 0.9660\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 26s 436us/sample - loss: 0.0775 - accuracy: 0.9714\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 29s 480us/sample - loss: 0.0655 - accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb0cc6090f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling and fittting the neural net\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train,\n",
    "         y_train, \n",
    "         epochs=10,\n",
    "          callbacks=[callbacks],\n",
    "          verbose=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
